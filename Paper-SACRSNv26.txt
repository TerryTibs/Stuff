
ğŸ” Peer Review / Audit Notes

The "Ethical" Layer (Verified):

Code: F.cross_entropy(row_logits, curr_sym) where row_logits comes from adjacency[prev_sym].

Verification: This is mathematically sound. It treats the Adjacency Matrix row as a probability distribution (logits) and penalizes the model if the current symbol transition doesn't match the "law" established by the graph. The paper correctly identifies this as "Normative" constraint.

Complex Activation (Clarification):

Code: ModReLU is implemented as z * (ReLU(|z| + b) / |z|).

Paper Adjustment: I have updated the formula in the paper to match this exactly. It effectively scales the magnitude without touching the phase.

Autograd Safety (Verified):

Code: with torch.no_grad(): model.prev_sym_soft.copy_(...).

Verification: This correctly fixes the "In-place operation" error common in PyTorch when using momentum buffers. The paper discussion on this is accurate.

Dream Mode (Nuance):

Code: Uses model.decoder(z_flat) directly on the codebook vectors.

Verification: This confirms the paper's claim that the logic is stored in the discrete graph, as the Dream Mode bypasses the encoder/input entirely.

Hyperparameters:

The paper stated act_threshold was 0.99. The code is 0.9999. I have corrected this precision in the paper.

SACRSN v21: Enforcing Normative Logic in Neuro-Symbolic Networks via Complex-Valued Topological Constraints

Abstract
Standard Recurrent Neural Networks (RNNs) and Transformers operate as probabilistic "black boxes," often failing to adhere to strict logical or structural rules. We present SACRSN v21, a neuro-symbolic architecture designed to learn and enforce a "Normative Topology"â€”a rigid set of transition rules derived from data. By integrating a Differentiable Stack for persistent memory, Complex-Valued Neural Networks (CVNNs) for phase-based context, and a novel Ethical Constraint Layer, we demonstrate a model that not only predicts text but actively detects deviations from its learned logic. We validate this on the Emerald Tablet dataset, showing that the model successfully reconstructs the cyclical logic of the text and quantifies "hallucinations" via topological stress.

1. Introduction

In classical Computer Science, a Finite State Machine (FSM) is deterministic: a transition from State A to State B is a binary rule. Deep Learning, conversely, is probabilistic. The danger in modern AI lies in the potential for "hallucination," where the model generates plausible but logically invalid sequences.

To bridge this gap, we introduce SACRSN v21, an architecture that imposes Normative Ethics on a neural network. In this context, "Ethics" defines a structural constraint (Nomos or Law): the strict adherence to a learned topological graph.

The v21 architecture introduces three critical improvements over standard recurrent models:

Complex-Valued Processing: Using the phase of complex numbers to encode semantic relations independent of signal magnitude.

Persistent Stack Memory: A differentiable stack allowing push/pop operations that persist across time steps.

Topological Anomaly Detection: A mechanism to mathematically quantify how "wrong" a specific input is based on the network's internal adjacency matrix.

2. Theoretical Architecture

The model operates on a sequence of tokens encoded into the complex plane 
ğ¶
C
.

2.1 The Complex Manifold

Standard neural networks use real numbers (
ğ‘…
R
). However, cyclical data requires orthogonal representations to distinguish identical tokens in different contexts. SACRSN v21 maps inputs to complex vectors 
ğ‘§
=
ğ‘Ÿ
ğ‘’
ğ‘–
ğœƒ
z=re
iÎ¸
.

We employ Complex Layer Normalization and ModReLU (Modular ReLU) activation [1]. Unlike standard ReLU, which zeroes out negative values (destroying phase information), ModReLU affects only the magnitude:

ModReLU
(
ğ‘§
)
=
ğ‘§
â‹…
ReLU
(
âˆ£
ğ‘§
âˆ£
+
ğ‘
)
âˆ£
ğ‘§
âˆ£
+
ğœ–
ModReLU(z)=zâ‹…
âˆ£zâˆ£+Ïµ
ReLU(âˆ£zâˆ£+b)
	â€‹


This ensures the "rotation" (context) of the data is preserved throughout the network layers, while the "magnitude" (feature strength) is non-linearly activated.

2.2 The Differentiable Stack

To enable recursive reasoning, we implement a continuous approximation of a Stack data structure [2].
At each step 
ğ‘¡
t
, the network outputs a control vector stack_ctrl defining three soft-gates: 
Push
Push
, 
Pop
Pop
, and 
NoOp
NoOp
. The stack pointer 
ğ‘ƒ
ğ‘¡
P
t
	â€‹

 is updated via convolution:

ğ‘ƒ
ğ‘¡
=
Push
â‹…
ğ‘ƒ
ğ‘¡
âˆ’
1
â†‘
+
Pop
â‹…
ğ‘ƒ
ğ‘¡
âˆ’
1
â†“
+
NoOp
â‹…
ğ‘ƒ
ğ‘¡
âˆ’
1
P
t
	â€‹

=Pushâ‹…P
tâˆ’1
â†‘
	â€‹

+Popâ‹…P
tâˆ’1
â†“
	â€‹

+NoOpâ‹…P
tâˆ’1
	â€‹


Crucially, the implementation in v21 is persistent: the stack state (stack_mem) is passed as a hidden state between batches, allowing the model to maintain long-term context beyond the immediate sequence window.

3. The "Ethical" Layer: Graph-Biased Vector Quantization

The core innovation of SACRSN v21 is the Ethical Constraint. In standard Vector Quantization (VQ), the network matches an input to a codebook symbol based solely on Euclidean distance. We augment this with a learned Adjacency Matrix (
ğ´
A
).

3.1 The Graph Bias

During the nearest-neighbor search, the distance metric 
ğ·
D
 is modified by the graph weights from the previous symbol (
ğ‘ 
ğ‘¡
âˆ’
1
s
tâˆ’1
	â€‹

):

ğ·
(
ğ‘§
,
ğ‘’
ğ‘–
)
=
âˆ£
âˆ£
ğ‘§
âˆ’
ğ‘’
ğ‘–
âˆ£
âˆ£
2
âˆ’
ğ›¼
â‹…
ğœ
(
ğ´
ğ‘ 
ğ‘¡
âˆ’
1
,
ğ‘–
)
D(z,e
i
	â€‹

)=âˆ£âˆ£zâˆ’e
i
	â€‹

âˆ£âˆ£
2
âˆ’Î±â‹…Ïƒ(A
s
tâˆ’1
	â€‹

,i
	â€‹

)

This makes logically valid next steps "magnetically attractive" in the vector space.

3.2 The Normative Loss Function

The model enforces logic via a dedicated loss term, implemented as Cross-Entropy between the Adjacency row and the chosen symbol:

ğ¿
ğ‘’
ğ‘¡
â„
ğ‘–
ğ‘
ğ‘ 
=
CrossEntropy
(
logits
=
ğ´
ğ‘ 
ğ‘¡
âˆ’
1
,
target
=
ğ‘ 
ğ‘¡
)
L
ethics
	â€‹

=CrossEntropy(logits=A
s
tâˆ’1
	â€‹

	â€‹

,target=s
t
	â€‹

)

Here, the Adjacency row 
ğ´
ğ‘ 
ğ‘¡
âˆ’
1
A
s
tâˆ’1
	â€‹

	â€‹

 is treated as the unnormalized probability distribution of allowed next steps. If the model selects a symbol 
ğ‘ 
ğ‘¡
s
t
	â€‹

 that has a low weight in the graph, the loss increases. This forces the network to align its discrete choices with its global topological map.

4. Methodology and Configuration

The model was trained using the following configuration, verified in the associated script:

Dimensions: 64 Complex (128 Real).

Adaptive Computation Time (ACT): Threshold 
ğœ
=
0.9999
Ï„=0.9999
. The model recurses up to 8 times per token until confidence is reached.

Stack Size: 16 slots.

Data: The Emerald Tablet, selected for its strict cyclical structure.

4.1 Stabilization Mechanisms

The architecture employs a Temporal Consistency Buffer (prev_sym_soft) to stabilize the adjacency learning. A crucial fix in v21 is Autograd Safety: the momentum update of this buffer is wrapped in a torch.no_grad() block, preventing the optimizer from attempting to backpropagate through the entire history of the training session.

5. Results and Analysis
5.1 X-Ray Topology (Graph Reconstruction)

The visualize_all routine extracts the Adjacency Matrix.

Result: The model successfully generated a directed graph where nodes representing "Above" were strongly connected to nodes representing "Below," mirroring the source text.

Significance: The graph edges represent causal rules (A 
â†’
â†’
 B) rather than mere co-occurrence, evidenced by the sparsity of the learned matrix.

5.2 The "Dream Mode" (System 2 Verification)

In "Dream Mode," the model relies exclusively on the Decoder and the Adjacency Matrix, bypassing the input encoder.

Observation: The model generated coherent pseudo-sentences ("True without falsehood...") by probabilistically walking the learned Adjacency graph.

Conclusion: This validates that the "logic" of the text was successfully extracted from the weights and externalized into the interpretable graph structure.

5.3 Anomaly Detection (The "Banana" Test)

We subjected the trained model to a corrupted sentence: "True without falsehood certain and most banana."

Metric: We measured the "Topological Violation Score" (the value of 
ğ¿
ğ‘’
ğ‘¡
â„
ğ‘–
ğ‘
ğ‘ 
L
ethics
	â€‹

).

Result: The score spiked significantly at the word "banana." Unlike standard perplexity (which measures surprise), this metric measures illegalityâ€”the transition violated the "laws" encoded in the Adjacency Matrix.

6. Conclusion

SACRSN v21 demonstrates that interpretability in neural networks need not be an afterthought. By integrating Complex-Valued logic for semantic encoding and Graph-Biased Vector Quantization for syntactic constraints, we created a "Glass Box" system.

The "Ethical" layer successfully enforced normative behavior, distinguishing between improbable events and impossible events. This architecture suggests a path forward for safety-critical AI, where models must not only generate text but also adhere to a strict, verifiable set of logical state transitions.

References

[1] Trabelsi, C., et al. (2018). "Deep Complex Networks." International Conference on Learning Representations (ICLR).

[2] Grefenstette, E., et al. (2015). "Learning to Transduce with Unbounded Memory." Advances in Neural Information Processing Systems.

[3] Graves, A. (2016). "Adaptive Computation Time for Recurrent Neural Networks." arXiv:1603.08983.

[4] Van den Oord, A., et al. (2017). "Neural Discrete Representation Learning." NIPS.
